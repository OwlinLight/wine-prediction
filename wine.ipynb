{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('Data/train.csv')\n",
    "test_data = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = data\n",
    "cols_to_filter = [col for col in wine.columns if col not in ['Id', 'density', 'pH', 'quality']]  # Define the columns to filter\n",
    "q3 = wine[cols_to_filter].quantile(0.75)  # Calculate the third quartile of each included column\n",
    "q1 = wine[cols_to_filter].quantile(0.25)  # Calculate the third quartile of each included column\n",
    "mask = (wine[cols_to_filter] <= q3+1.5*(q3-q1)).all(axis=1)  # Create a mask that selects only the rows where included columns are less than or equal to Q3\n",
    "wine = wine[mask]  # Remove rows where included columns are greater than Q3\n",
    "y = wine['quality']\n",
    "X = wine.drop(['quality', 'Id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "# Create a KFold object to split the dataset into training and testing folds\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "# Initialize an empty list to store the accuracies\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = SVC(C=1.2, gamma=0.9, kernel='rbf')\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "# Loop over the folds and train/test the classifier on each fold\n",
    "for fold, (train_indices, test_indices) in enumerate(kfold.split(X, y)):\n",
    "    # Get the training and testing data for this fold\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train the classifier on the training set\n",
    "    ada_boost.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy of the classifier for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print the accuracy for this fold\n",
    "    print(\"Fold {}: Accuracy: {:.2f}%\".format(fold + 1, accuracy * 100))\n",
    "\n",
    "    # Add the accuracy to the list of accuracies\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy over all folds\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "# Print the average accuracy\n",
    "print(\"Average accuracy: {:.2f}%\".format(avg_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id = test_data['Id']\n",
    "X_test = test_data.drop(['Id'], axis=1)\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "c1 = y_id.to_frame()\n",
    "c2 = pd.DataFrame({'quality': y_pred})\n",
    "df = pd.concat([c1, c2], axis = 1)\n",
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
